{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will train and test classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../../data/dataset.csv\"\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of       Price_Change  Target\n",
       "0        -0.000410       0\n",
       "1         0.001395       0\n",
       "2         0.000082       0\n",
       "3        -0.000492       0\n",
       "4        -0.000738       0\n",
       "...            ...     ...\n",
       "4199      0.000244       0\n",
       "4200     -0.000163       0\n",
       "4201      0.000366       0\n",
       "4202     -0.000692       0\n",
       "4203      0.000407       0\n",
       "\n",
       "[4204 rows x 2 columns]>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['open', 'close', 'high', 'low', 'Target']\n",
    "data = df\n",
    "data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.iloc[:, -1]  \n",
    "X = data.iloc[:, :-1]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_index = int(len(X) * 0.75)\n",
    "\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "y_train, y_test = y[:split_index], y[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)  \n",
    "X_test = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5252\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.54      0.56       579\n",
      "           1       0.47      0.51      0.49       472\n",
      "\n",
      "    accuracy                           0.53      1051\n",
      "   macro avg       0.52      0.52      0.52      1051\n",
      "weighted avg       0.53      0.53      0.53      1051\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[313 266]\n",
      " [233 239]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest Classifier:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5252\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.54      0.56       579\n",
      "           1       0.47      0.51      0.49       472\n",
      "\n",
      "    accuracy                           0.53      1051\n",
      "   macro avg       0.52      0.52      0.52      1051\n",
      "weighted avg       0.53      0.53      0.53      1051\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[313 266]\n",
      " [233 239]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBoost Classifier:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.5785\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.46      0.55       579\n",
      "           1       0.52      0.72      0.61       472\n",
      "\n",
      "    accuracy                           0.58      1051\n",
      "   macro avg       0.60      0.59      0.58      1051\n",
      "weighted avg       0.60      0.58      0.57      1051\n",
      "\n",
      "\n",
      "XGBoost Confusion Matrix:\n",
      "[[266 313]\n",
      " [130 342]]\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_model = XGBClassifier(random_state=42, n_estimators=100, max_depth=4)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost Accuracy: {accuracy_xgb:.4f}\")\n",
    "(\"\\nXGBoost Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "print(\"\\nXGBoost Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Logistic Regression:****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.6156\n",
      "\n",
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.58      0.62       579\n",
      "           1       0.56      0.66      0.61       472\n",
      "\n",
      "    accuracy                           0.62      1051\n",
      "   macro avg       0.62      0.62      0.62      1051\n",
      "weighted avg       0.63      0.62      0.62      1051\n",
      "\n",
      "\n",
      "Logistic Regression Confusion Matrix:\n",
      "[[334 245]\n",
      " [159 313]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg_model = LogisticRegression(max_iter=10000)\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_logreg = logreg_model.predict(X_test)\n",
    "\n",
    "accuracy_logreg = accuracy_score(y_test, y_pred_logreg)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy_logreg:.4f}\")\n",
    "print(\"\\nLogistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_logreg))\n",
    "print(\"\\nLogistic Regression Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_logreg))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for regression, we have to firstly scale data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVM:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.6118\n",
      "\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.57      0.62       579\n",
      "           1       0.56      0.66      0.60       472\n",
      "\n",
      "    accuracy                           0.61      1051\n",
      "   macro avg       0.62      0.62      0.61      1051\n",
      "weighted avg       0.62      0.61      0.61      1051\n",
      "\n",
      "\n",
      "SVM Confusion Matrix:\n",
      "[[331 248]\n",
      " [160 312]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(f\"SVM Accuracy: {accuracy_svm:.4f}\")\n",
    "print(\"\\nSVM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "print(\"\\nSVM Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LSTM:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-25 10:24:01.652130: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-25 10:24:01.662804: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-25 10:24:01.744362: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-25 10:24:01.833223: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1737797041.934064    5598 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1737797041.962780    5598 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-25 10:24:02.156261: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "W0000 00:00:1737797047.158810    5598 gpu_device.cc:2344] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "/home/pedro/python_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.5104 - loss: 0.6933 - val_accuracy: 0.5395 - val_loss: 0.6920\n",
      "Epoch 2/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5319 - loss: 0.6921 - val_accuracy: 0.5387 - val_loss: 0.6913\n",
      "Epoch 3/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5202 - loss: 0.6907 - val_accuracy: 0.5378 - val_loss: 0.6916\n",
      "Epoch 4/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5311 - loss: 0.6920 - val_accuracy: 0.5352 - val_loss: 0.6919\n",
      "Epoch 5/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5201 - loss: 0.6914 - val_accuracy: 0.5239 - val_loss: 0.6921\n",
      "Epoch 6/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5248 - loss: 0.6926 - val_accuracy: 0.5161 - val_loss: 0.6922\n",
      "Epoch 7/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5209 - loss: 0.6924 - val_accuracy: 0.5369 - val_loss: 0.6918\n",
      "Epoch 8/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5395 - loss: 0.6915 - val_accuracy: 0.5126 - val_loss: 0.6923\n",
      "Epoch 9/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5236 - loss: 0.6901 - val_accuracy: 0.5126 - val_loss: 0.6923\n",
      "Epoch 10/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5180 - loss: 0.6911 - val_accuracy: 0.5117 - val_loss: 0.6925\n",
      "Epoch 11/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5337 - loss: 0.6900 - val_accuracy: 0.5091 - val_loss: 0.6927\n",
      "Epoch 12/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5281 - loss: 0.6913 - val_accuracy: 0.5074 - val_loss: 0.6927\n",
      "Epoch 13/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5239 - loss: 0.6909 - val_accuracy: 0.5039 - val_loss: 0.6931\n",
      "Epoch 14/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5407 - loss: 0.6900 - val_accuracy: 0.5030 - val_loss: 0.6930\n",
      "Epoch 15/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5379 - loss: 0.6905 - val_accuracy: 0.5091 - val_loss: 0.6927\n",
      "Epoch 16/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5275 - loss: 0.6909 - val_accuracy: 0.4987 - val_loss: 0.6930\n",
      "Epoch 17/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5237 - loss: 0.6915 - val_accuracy: 0.5100 - val_loss: 0.6926\n",
      "Epoch 18/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5393 - loss: 0.6904 - val_accuracy: 0.5030 - val_loss: 0.6930\n",
      "Epoch 19/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5310 - loss: 0.6913 - val_accuracy: 0.4996 - val_loss: 0.6933\n",
      "Epoch 20/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5337 - loss: 0.6896 - val_accuracy: 0.5013 - val_loss: 0.6931\n",
      "Epoch 21/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5366 - loss: 0.6906 - val_accuracy: 0.5039 - val_loss: 0.6932\n",
      "Epoch 22/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5228 - loss: 0.6925 - val_accuracy: 0.5013 - val_loss: 0.6932\n",
      "Epoch 23/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5244 - loss: 0.6910 - val_accuracy: 0.5013 - val_loss: 0.6931\n",
      "Epoch 24/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5154 - loss: 0.6909 - val_accuracy: 0.5039 - val_loss: 0.6933\n",
      "Epoch 25/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5098 - loss: 0.6919 - val_accuracy: 0.5030 - val_loss: 0.6931\n",
      "Epoch 26/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5244 - loss: 0.6892 - val_accuracy: 0.5004 - val_loss: 0.6935\n",
      "Epoch 27/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5210 - loss: 0.6913 - val_accuracy: 0.5004 - val_loss: 0.6931\n",
      "Epoch 28/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5343 - loss: 0.6885 - val_accuracy: 0.4987 - val_loss: 0.6933\n",
      "Epoch 29/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5289 - loss: 0.6903 - val_accuracy: 0.5030 - val_loss: 0.6932\n",
      "Epoch 30/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5188 - loss: 0.6900 - val_accuracy: 0.4996 - val_loss: 0.6932\n",
      "Epoch 31/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5142 - loss: 0.6921 - val_accuracy: 0.5039 - val_loss: 0.6931\n",
      "Epoch 32/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5232 - loss: 0.6905 - val_accuracy: 0.5004 - val_loss: 0.6932\n",
      "Epoch 33/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5309 - loss: 0.6895 - val_accuracy: 0.4952 - val_loss: 0.6934\n",
      "Epoch 34/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5238 - loss: 0.6909 - val_accuracy: 0.4996 - val_loss: 0.6936\n",
      "Epoch 35/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5212 - loss: 0.6897 - val_accuracy: 0.4978 - val_loss: 0.6935\n",
      "Epoch 36/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5156 - loss: 0.6909 - val_accuracy: 0.4970 - val_loss: 0.6934\n",
      "Epoch 37/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5151 - loss: 0.6912 - val_accuracy: 0.4970 - val_loss: 0.6935\n",
      "Epoch 38/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5200 - loss: 0.6888 - val_accuracy: 0.4978 - val_loss: 0.6935\n",
      "Epoch 39/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5100 - loss: 0.6903 - val_accuracy: 0.5013 - val_loss: 0.6932\n",
      "Epoch 40/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5211 - loss: 0.6918 - val_accuracy: 0.5022 - val_loss: 0.6933\n",
      "Epoch 41/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5205 - loss: 0.6907 - val_accuracy: 0.4978 - val_loss: 0.6935\n",
      "Epoch 42/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5216 - loss: 0.6910 - val_accuracy: 0.4978 - val_loss: 0.6935\n",
      "Epoch 43/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5027 - loss: 0.6921 - val_accuracy: 0.5013 - val_loss: 0.6934\n",
      "Epoch 44/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5128 - loss: 0.6916 - val_accuracy: 0.5013 - val_loss: 0.6933\n",
      "Epoch 45/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5213 - loss: 0.6911 - val_accuracy: 0.4970 - val_loss: 0.6935\n",
      "Epoch 46/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5056 - loss: 0.6921 - val_accuracy: 0.4996 - val_loss: 0.6934\n",
      "Epoch 47/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5192 - loss: 0.6915 - val_accuracy: 0.5022 - val_loss: 0.6934\n",
      "Epoch 48/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5348 - loss: 0.6899 - val_accuracy: 0.4978 - val_loss: 0.6934\n",
      "Epoch 49/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5317 - loss: 0.6907 - val_accuracy: 0.5004 - val_loss: 0.6934\n",
      "Epoch 50/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5296 - loss: 0.6892 - val_accuracy: 0.4996 - val_loss: 0.6937\n",
      "Epoch 51/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5157 - loss: 0.6916 - val_accuracy: 0.4996 - val_loss: 0.6935\n",
      "Epoch 52/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5287 - loss: 0.6891 - val_accuracy: 0.4996 - val_loss: 0.6935\n",
      "Epoch 53/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5184 - loss: 0.6902 - val_accuracy: 0.5004 - val_loss: 0.6934\n",
      "Epoch 54/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5309 - loss: 0.6905 - val_accuracy: 0.5013 - val_loss: 0.6934\n",
      "Epoch 55/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5026 - loss: 0.6927 - val_accuracy: 0.5022 - val_loss: 0.6934\n",
      "Epoch 56/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5176 - loss: 0.6913 - val_accuracy: 0.5004 - val_loss: 0.6932\n",
      "Epoch 57/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5218 - loss: 0.6908 - val_accuracy: 0.5013 - val_loss: 0.6932\n",
      "Epoch 58/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5326 - loss: 0.6903 - val_accuracy: 0.5004 - val_loss: 0.6932\n",
      "Epoch 59/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5279 - loss: 0.6907 - val_accuracy: 0.4987 - val_loss: 0.6932\n",
      "Epoch 60/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5274 - loss: 0.6904 - val_accuracy: 0.4987 - val_loss: 0.6936\n",
      "Epoch 61/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5124 - loss: 0.6908 - val_accuracy: 0.4970 - val_loss: 0.6934\n",
      "Epoch 62/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5200 - loss: 0.6904 - val_accuracy: 0.4987 - val_loss: 0.6936\n",
      "Epoch 63/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5098 - loss: 0.6898 - val_accuracy: 0.4996 - val_loss: 0.6934\n",
      "Epoch 64/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5228 - loss: 0.6914 - val_accuracy: 0.4978 - val_loss: 0.6935\n",
      "Epoch 65/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5018 - loss: 0.6924 - val_accuracy: 0.5004 - val_loss: 0.6934\n",
      "Epoch 66/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5220 - loss: 0.6907 - val_accuracy: 0.4970 - val_loss: 0.6935\n",
      "Epoch 67/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5380 - loss: 0.6889 - val_accuracy: 0.4970 - val_loss: 0.6934\n",
      "Epoch 68/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5067 - loss: 0.6913 - val_accuracy: 0.5022 - val_loss: 0.6936\n",
      "Epoch 69/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5163 - loss: 0.6922 - val_accuracy: 0.5004 - val_loss: 0.6939\n",
      "Epoch 70/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5182 - loss: 0.6902 - val_accuracy: 0.4970 - val_loss: 0.6935\n",
      "Epoch 71/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5196 - loss: 0.6904 - val_accuracy: 0.4987 - val_loss: 0.6935\n",
      "Epoch 72/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5341 - loss: 0.6888 - val_accuracy: 0.4987 - val_loss: 0.6936\n",
      "Epoch 73/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5124 - loss: 0.6914 - val_accuracy: 0.4970 - val_loss: 0.6935\n",
      "Epoch 74/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5210 - loss: 0.6898 - val_accuracy: 0.4970 - val_loss: 0.6935\n",
      "Epoch 75/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5298 - loss: 0.6899 - val_accuracy: 0.5048 - val_loss: 0.6934\n",
      "Epoch 76/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5202 - loss: 0.6926 - val_accuracy: 0.5004 - val_loss: 0.6934\n",
      "Epoch 77/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5232 - loss: 0.6898 - val_accuracy: 0.5056 - val_loss: 0.6933\n",
      "Epoch 78/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5302 - loss: 0.6880 - val_accuracy: 0.5030 - val_loss: 0.6936\n",
      "Epoch 79/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5001 - loss: 0.6917 - val_accuracy: 0.4978 - val_loss: 0.6937\n",
      "Epoch 80/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5157 - loss: 0.6913 - val_accuracy: 0.4970 - val_loss: 0.6935\n",
      "Epoch 81/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4978 - loss: 0.6915 - val_accuracy: 0.4996 - val_loss: 0.6937\n",
      "Epoch 82/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5146 - loss: 0.6914 - val_accuracy: 0.5013 - val_loss: 0.6932\n",
      "Epoch 83/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5254 - loss: 0.6900 - val_accuracy: 0.5013 - val_loss: 0.6937\n",
      "Epoch 84/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5265 - loss: 0.6906 - val_accuracy: 0.4978 - val_loss: 0.6935\n",
      "Epoch 85/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5273 - loss: 0.6912 - val_accuracy: 0.5030 - val_loss: 0.6937\n",
      "Epoch 86/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5044 - loss: 0.6920 - val_accuracy: 0.5039 - val_loss: 0.6933\n",
      "Epoch 87/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5250 - loss: 0.6886 - val_accuracy: 0.4987 - val_loss: 0.6936\n",
      "Epoch 88/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5120 - loss: 0.6924 - val_accuracy: 0.4987 - val_loss: 0.6934\n",
      "Epoch 89/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5183 - loss: 0.6909 - val_accuracy: 0.4987 - val_loss: 0.6934\n",
      "Epoch 90/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5155 - loss: 0.6912 - val_accuracy: 0.4987 - val_loss: 0.6934\n",
      "Epoch 91/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5216 - loss: 0.6896 - val_accuracy: 0.4996 - val_loss: 0.6938\n",
      "Epoch 92/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5209 - loss: 0.6902 - val_accuracy: 0.5030 - val_loss: 0.6937\n",
      "Epoch 93/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5267 - loss: 0.6913 - val_accuracy: 0.5022 - val_loss: 0.6933\n",
      "Epoch 94/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5165 - loss: 0.6919 - val_accuracy: 0.4996 - val_loss: 0.6932\n",
      "Epoch 95/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5300 - loss: 0.6898 - val_accuracy: 0.5022 - val_loss: 0.6933\n",
      "Epoch 96/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5353 - loss: 0.6886 - val_accuracy: 0.5013 - val_loss: 0.6936\n",
      "Epoch 97/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5215 - loss: 0.6917 - val_accuracy: 0.4970 - val_loss: 0.6935\n",
      "Epoch 98/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5107 - loss: 0.6919 - val_accuracy: 0.4970 - val_loss: 0.6935\n",
      "Epoch 99/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5267 - loss: 0.6893 - val_accuracy: 0.4961 - val_loss: 0.6935\n",
      "Epoch 100/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5077 - loss: 0.6922 - val_accuracy: 0.5004 - val_loss: 0.6932\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "LSTM Accuracy: 0.5004\n",
      "\n",
      "LSTM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.40      0.46       611\n",
      "           1       0.47      0.61      0.53       540\n",
      "\n",
      "    accuracy                           0.50      1151\n",
      "   macro avg       0.51      0.51      0.50      1151\n",
      "weighted avg       0.51      0.50      0.50      1151\n",
      "\n",
      "\n",
      "LSTM Confusion Matrix:\n",
      "[[246 365]\n",
      " [210 330]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Tworzenie modelu LSTM\n",
    "lstm_model = Sequential()\n",
    "\n",
    "# Dodaj warstwę LSTM\n",
    "lstm_model.add(LSTM(units=50, return_sequences=False, input_shape=(X_train.shape[1], 1)))\n",
    "\n",
    "# Dodaj warstwę Dropout dla zapobiegania overfittingowi\n",
    "lstm_model.add(Dropout(0.2))\n",
    "\n",
    "# Dodaj warstwę Dense (wyjściowa warstwa klasyfikatora)\n",
    "lstm_model.add(Dense(units=1, activation='sigmoid'))  # Zakładając klasyfikację binarną\n",
    "\n",
    "# Kompilowanie modelu\n",
    "lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Trenowanie modelu\n",
    "lstm_model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Predykcja na zbiorze testowym\n",
    "y_pred_lstm = (lstm_model.predict(X_test) > 0.5).astype(int)\n",
    "\n",
    "# Ocena modelu\n",
    "accuracy_lstm = accuracy_score(y_test, y_pred_lstm)\n",
    "print(f\"LSTM Accuracy: {accuracy_lstm:.4f}\")\n",
    "print(\"\\nLSTM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_lstm))\n",
    "print(\"\\nLSTM Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_lstm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Neural Network:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pedro/python_env/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5064 - loss: 0.6939 - val_accuracy: 0.5248 - val_loss: 0.6928\n",
      "Epoch 2/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5128 - loss: 0.6934 - val_accuracy: 0.5216 - val_loss: 0.6928\n",
      "Epoch 3/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4837 - loss: 0.6949 - val_accuracy: 0.5216 - val_loss: 0.6928\n",
      "Epoch 4/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5038 - loss: 0.6925 - val_accuracy: 0.5112 - val_loss: 0.6928\n",
      "Epoch 5/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5135 - loss: 0.6932 - val_accuracy: 0.5216 - val_loss: 0.6928\n",
      "Epoch 6/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5058 - loss: 0.6934 - val_accuracy: 0.5216 - val_loss: 0.6930\n",
      "Epoch 7/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5190 - loss: 0.6928 - val_accuracy: 0.5256 - val_loss: 0.6931\n",
      "Epoch 8/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4995 - loss: 0.6933 - val_accuracy: 0.5040 - val_loss: 0.6931\n",
      "Epoch 9/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5203 - loss: 0.6925 - val_accuracy: 0.5192 - val_loss: 0.6930\n",
      "Epoch 10/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4960 - loss: 0.6936 - val_accuracy: 0.5120 - val_loss: 0.6930\n",
      "Epoch 11/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5176 - loss: 0.6926 - val_accuracy: 0.5216 - val_loss: 0.6931\n",
      "Epoch 12/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5157 - loss: 0.6933 - val_accuracy: 0.5136 - val_loss: 0.6931\n",
      "Epoch 13/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4943 - loss: 0.6931 - val_accuracy: 0.5088 - val_loss: 0.6932\n",
      "Epoch 14/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4997 - loss: 0.6944 - val_accuracy: 0.5216 - val_loss: 0.6931\n",
      "Epoch 15/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5073 - loss: 0.6932 - val_accuracy: 0.5120 - val_loss: 0.6930\n",
      "Epoch 16/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5190 - loss: 0.6928 - val_accuracy: 0.5112 - val_loss: 0.6930\n",
      "Epoch 17/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5022 - loss: 0.6932 - val_accuracy: 0.5008 - val_loss: 0.6932\n",
      "Epoch 18/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5069 - loss: 0.6932 - val_accuracy: 0.5032 - val_loss: 0.6931\n",
      "Epoch 19/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5055 - loss: 0.6931 - val_accuracy: 0.5120 - val_loss: 0.6930\n",
      "Epoch 20/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5034 - loss: 0.6938 - val_accuracy: 0.5216 - val_loss: 0.6930\n",
      "Epoch 21/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5038 - loss: 0.6931 - val_accuracy: 0.5216 - val_loss: 0.6931\n",
      "Epoch 22/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5109 - loss: 0.6928 - val_accuracy: 0.5032 - val_loss: 0.6931\n",
      "Epoch 23/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5094 - loss: 0.6929 - val_accuracy: 0.5208 - val_loss: 0.6929\n",
      "Epoch 24/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5105 - loss: 0.6924 - val_accuracy: 0.5096 - val_loss: 0.6933\n",
      "Epoch 25/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5156 - loss: 0.6931 - val_accuracy: 0.5224 - val_loss: 0.6930\n",
      "Epoch 26/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6919 - val_accuracy: 0.5048 - val_loss: 0.6932\n",
      "Epoch 27/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5157 - loss: 0.6931 - val_accuracy: 0.5216 - val_loss: 0.6931\n",
      "Epoch 28/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5068 - loss: 0.6926 - val_accuracy: 0.5000 - val_loss: 0.6930\n",
      "Epoch 29/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5134 - loss: 0.6928 - val_accuracy: 0.5016 - val_loss: 0.6930\n",
      "Epoch 30/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5016 - loss: 0.6932 - val_accuracy: 0.5216 - val_loss: 0.6929\n",
      "Epoch 31/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5011 - loss: 0.6937 - val_accuracy: 0.5216 - val_loss: 0.6931\n",
      "Epoch 32/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5241 - loss: 0.6922 - val_accuracy: 0.5072 - val_loss: 0.6931\n",
      "Epoch 33/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5079 - loss: 0.6929 - val_accuracy: 0.5048 - val_loss: 0.6931\n",
      "Epoch 34/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5219 - loss: 0.6924 - val_accuracy: 0.4984 - val_loss: 0.6930\n",
      "Epoch 35/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5077 - loss: 0.6931 - val_accuracy: 0.5216 - val_loss: 0.6931\n",
      "Epoch 36/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4958 - loss: 0.6933 - val_accuracy: 0.5256 - val_loss: 0.6931\n",
      "Epoch 37/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5124 - loss: 0.6921 - val_accuracy: 0.4984 - val_loss: 0.6929\n",
      "Epoch 38/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5146 - loss: 0.6928 - val_accuracy: 0.5216 - val_loss: 0.6929\n",
      "Epoch 39/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5091 - loss: 0.6935 - val_accuracy: 0.5176 - val_loss: 0.6929\n",
      "Epoch 40/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5128 - loss: 0.6937 - val_accuracy: 0.5208 - val_loss: 0.6929\n",
      "Epoch 41/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5091 - loss: 0.6930 - val_accuracy: 0.5040 - val_loss: 0.6930\n",
      "Epoch 42/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5071 - loss: 0.6929 - val_accuracy: 0.5240 - val_loss: 0.6928\n",
      "Epoch 43/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5100 - loss: 0.6930 - val_accuracy: 0.5128 - val_loss: 0.6929\n",
      "Epoch 44/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5167 - loss: 0.6929 - val_accuracy: 0.5120 - val_loss: 0.6929\n",
      "Epoch 45/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5047 - loss: 0.6932 - val_accuracy: 0.5216 - val_loss: 0.6929\n",
      "Epoch 46/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5016 - loss: 0.6932 - val_accuracy: 0.5160 - val_loss: 0.6929\n",
      "Epoch 47/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5128 - loss: 0.6931 - val_accuracy: 0.5128 - val_loss: 0.6929\n",
      "Epoch 48/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5172 - loss: 0.6926 - val_accuracy: 0.5040 - val_loss: 0.6931\n",
      "Epoch 49/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5028 - loss: 0.6936 - val_accuracy: 0.5088 - val_loss: 0.6930\n",
      "Epoch 50/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5028 - loss: 0.6927 - val_accuracy: 0.5056 - val_loss: 0.6928\n",
      "Epoch 51/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5119 - loss: 0.6923 - val_accuracy: 0.5224 - val_loss: 0.6929\n",
      "Epoch 52/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5256 - loss: 0.6922 - val_accuracy: 0.5056 - val_loss: 0.6929\n",
      "Epoch 53/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5022 - loss: 0.6935 - val_accuracy: 0.5192 - val_loss: 0.6928\n",
      "Epoch 54/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5220 - loss: 0.6926 - val_accuracy: 0.5120 - val_loss: 0.6928\n",
      "Epoch 55/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5030 - loss: 0.6929 - val_accuracy: 0.5104 - val_loss: 0.6929\n",
      "Epoch 56/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5060 - loss: 0.6926 - val_accuracy: 0.5240 - val_loss: 0.6928\n",
      "Epoch 57/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5149 - loss: 0.6921 - val_accuracy: 0.5016 - val_loss: 0.6928\n",
      "Epoch 58/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5234 - loss: 0.6918 - val_accuracy: 0.5184 - val_loss: 0.6929\n",
      "Epoch 59/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5098 - loss: 0.6928 - val_accuracy: 0.5088 - val_loss: 0.6928\n",
      "Epoch 60/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5016 - loss: 0.6928 - val_accuracy: 0.5096 - val_loss: 0.6928\n",
      "Epoch 61/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5122 - loss: 0.6926 - val_accuracy: 0.5064 - val_loss: 0.6927\n",
      "Epoch 62/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5022 - loss: 0.6928 - val_accuracy: 0.5248 - val_loss: 0.6927\n",
      "Epoch 63/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5169 - loss: 0.6925 - val_accuracy: 0.5096 - val_loss: 0.6928\n",
      "Epoch 64/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5077 - loss: 0.6930 - val_accuracy: 0.5088 - val_loss: 0.6927\n",
      "Epoch 65/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4932 - loss: 0.6931 - val_accuracy: 0.5072 - val_loss: 0.6927\n",
      "Epoch 66/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5086 - loss: 0.6933 - val_accuracy: 0.5088 - val_loss: 0.6928\n",
      "Epoch 67/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5143 - loss: 0.6924 - val_accuracy: 0.5104 - val_loss: 0.6927\n",
      "Epoch 68/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5132 - loss: 0.6931 - val_accuracy: 0.5064 - val_loss: 0.6928\n",
      "Epoch 69/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4995 - loss: 0.6934 - val_accuracy: 0.5224 - val_loss: 0.6926\n",
      "Epoch 70/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5077 - loss: 0.6920 - val_accuracy: 0.5216 - val_loss: 0.6926\n",
      "Epoch 71/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5137 - loss: 0.6924 - val_accuracy: 0.5120 - val_loss: 0.6926\n",
      "Epoch 72/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5134 - loss: 0.6927 - val_accuracy: 0.5112 - val_loss: 0.6927\n",
      "Epoch 73/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5200 - loss: 0.6921 - val_accuracy: 0.5040 - val_loss: 0.6928\n",
      "Epoch 74/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5062 - loss: 0.6927 - val_accuracy: 0.5048 - val_loss: 0.6927\n",
      "Epoch 75/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5075 - loss: 0.6925 - val_accuracy: 0.5024 - val_loss: 0.6926\n",
      "Epoch 76/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5227 - loss: 0.6926 - val_accuracy: 0.5216 - val_loss: 0.6927\n",
      "Epoch 77/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5000 - loss: 0.6932 - val_accuracy: 0.5080 - val_loss: 0.6927\n",
      "Epoch 78/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4924 - loss: 0.6928 - val_accuracy: 0.5072 - val_loss: 0.6926\n",
      "Epoch 79/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5018 - loss: 0.6930 - val_accuracy: 0.5112 - val_loss: 0.6928\n",
      "Epoch 80/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5117 - loss: 0.6922 - val_accuracy: 0.5232 - val_loss: 0.6927\n",
      "Epoch 81/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5206 - loss: 0.6921 - val_accuracy: 0.5056 - val_loss: 0.6928\n",
      "Epoch 82/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5158 - loss: 0.6923 - val_accuracy: 0.5104 - val_loss: 0.6927\n",
      "Epoch 83/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5114 - loss: 0.6927 - val_accuracy: 0.5176 - val_loss: 0.6928\n",
      "Epoch 84/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4930 - loss: 0.6930 - val_accuracy: 0.5112 - val_loss: 0.6928\n",
      "Epoch 85/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5028 - loss: 0.6928 - val_accuracy: 0.5128 - val_loss: 0.6926\n",
      "Epoch 86/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5203 - loss: 0.6922 - val_accuracy: 0.5104 - val_loss: 0.6927\n",
      "Epoch 87/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5251 - loss: 0.6923 - val_accuracy: 0.5120 - val_loss: 0.6927\n",
      "Epoch 88/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5063 - loss: 0.6936 - val_accuracy: 0.5056 - val_loss: 0.6927\n",
      "Epoch 89/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5045 - loss: 0.6940 - val_accuracy: 0.5104 - val_loss: 0.6926\n",
      "Epoch 90/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5081 - loss: 0.6924 - val_accuracy: 0.5128 - val_loss: 0.6926\n",
      "Epoch 91/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4959 - loss: 0.6931 - val_accuracy: 0.5056 - val_loss: 0.6925\n",
      "Epoch 92/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5177 - loss: 0.6925 - val_accuracy: 0.5144 - val_loss: 0.6926\n",
      "Epoch 93/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5026 - loss: 0.6924 - val_accuracy: 0.5072 - val_loss: 0.6926\n",
      "Epoch 94/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5197 - loss: 0.6921 - val_accuracy: 0.5080 - val_loss: 0.6926\n",
      "Epoch 95/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5170 - loss: 0.6925 - val_accuracy: 0.5048 - val_loss: 0.6926\n",
      "Epoch 96/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5206 - loss: 0.6924 - val_accuracy: 0.5144 - val_loss: 0.6925\n",
      "Epoch 97/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5210 - loss: 0.6931 - val_accuracy: 0.5112 - val_loss: 0.6925\n",
      "Epoch 98/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5048 - loss: 0.6930 - val_accuracy: 0.5144 - val_loss: 0.6925\n",
      "Epoch 99/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5237 - loss: 0.6920 - val_accuracy: 0.5088 - val_loss: 0.6925\n",
      "Epoch 100/100\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5120 - loss: 0.6927 - val_accuracy: 0.5112 - val_loss: 0.6925\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step\n",
      "Neural Network Accuracy: 0.5112\n",
      "\n",
      "Neural Network Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.88      0.65       651\n",
      "           1       0.46      0.11      0.18       597\n",
      "\n",
      "    accuracy                           0.51      1248\n",
      "   macro avg       0.49      0.49      0.42      1248\n",
      "weighted avg       0.49      0.51      0.43      1248\n",
      "\n",
      "\n",
      "Neural Network Confusion Matrix:\n",
      "[[571  80]\n",
      " [530  67]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_nn = (model.predict(X_test) > 0.5).astype(int)\n",
    "\n",
    "accuracy_nn = accuracy_score(y_test, y_pred_nn)\n",
    "print(f\"Neural Network Accuracy: {accuracy_nn:.4f}\")\n",
    "print(\"\\nNeural Network Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_nn))\n",
    "print(\"\\nNeural Network Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.25, random_state=42\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
