{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will train and test classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../../data/dataset.csv\"\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of       SMA_20_Distance  Target\n",
       "0            0.003228       1\n",
       "1            0.001865       0\n",
       "2            0.001924       0\n",
       "3            0.001314       0\n",
       "4            0.001402       0\n",
       "...               ...     ...\n",
       "4597         0.005641       0\n",
       "4598         0.006000       0\n",
       "4599         0.007279       0\n",
       "4600         0.006758       0\n",
       "4601         0.002450       0\n",
       "\n",
       "[4602 rows x 2 columns]>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['open', 'close', 'high', 'low', 'Target']\n",
    "data = df\n",
    "data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.iloc[:, -1]  \n",
    "X = data.iloc[:, :-1]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_index = int(len(X) * 0.75)\n",
    "\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "y_train, y_test = y[:split_index], y[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)  \n",
    "X_test = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5838\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.59      0.59       592\n",
      "           1       0.57      0.58      0.57       559\n",
      "\n",
      "    accuracy                           0.58      1151\n",
      "   macro avg       0.58      0.58      0.58      1151\n",
      "weighted avg       0.58      0.58      0.58      1151\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[349 243]\n",
      " [236 323]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest Classifier:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5838\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.59      0.59       592\n",
      "           1       0.57      0.58      0.57       559\n",
      "\n",
      "    accuracy                           0.58      1151\n",
      "   macro avg       0.58      0.58      0.58      1151\n",
      "weighted avg       0.58      0.58      0.58      1151\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[349 243]\n",
      " [236 323]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBoost Classifier:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.6525\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.62      0.65       592\n",
      "           1       0.63      0.69      0.66       559\n",
      "\n",
      "    accuracy                           0.65      1151\n",
      "   macro avg       0.65      0.65      0.65      1151\n",
      "weighted avg       0.65      0.65      0.65      1151\n",
      "\n",
      "\n",
      "XGBoost Confusion Matrix:\n",
      "[[366 226]\n",
      " [174 385]]\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_model = XGBClassifier(random_state=42, n_estimators=100, max_depth=4)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost Accuracy: {accuracy_xgb:.4f}\")\n",
    "(\"\\nXGBoost Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "print(\"\\nXGBoost Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Logistic Regression:****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.6733\n",
      "\n",
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.66      0.68       592\n",
      "           1       0.66      0.69      0.67       559\n",
      "\n",
      "    accuracy                           0.67      1151\n",
      "   macro avg       0.67      0.67      0.67      1151\n",
      "weighted avg       0.67      0.67      0.67      1151\n",
      "\n",
      "\n",
      "Logistic Regression Confusion Matrix:\n",
      "[[391 201]\n",
      " [175 384]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg_model = LogisticRegression(max_iter=10000)\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_logreg = logreg_model.predict(X_test)\n",
    "\n",
    "accuracy_logreg = accuracy_score(y_test, y_pred_logreg)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy_logreg:.4f}\")\n",
    "print(\"\\nLogistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_logreg))\n",
    "print(\"\\nLogistic Regression Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_logreg))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for regression, we have to firstly scale data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVM:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.6725\n",
      "\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68       592\n",
      "           1       0.66      0.66      0.66       559\n",
      "\n",
      "    accuracy                           0.67      1151\n",
      "   macro avg       0.67      0.67      0.67      1151\n",
      "weighted avg       0.67      0.67      0.67      1151\n",
      "\n",
      "\n",
      "SVM Confusion Matrix:\n",
      "[[404 188]\n",
      " [189 370]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(f\"SVM Accuracy: {accuracy_svm:.4f}\")\n",
    "print(\"\\nSVM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "print(\"\\nSVM Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LSTM:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pedro/python_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.4977 - loss: 0.6919 - val_accuracy: 0.5908 - val_loss: 0.6780\n",
      "Epoch 2/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6594 - loss: 0.6559 - val_accuracy: 0.6337 - val_loss: 0.6579\n",
      "Epoch 3/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6565 - loss: 0.6203 - val_accuracy: 0.6417 - val_loss: 0.6468\n",
      "Epoch 4/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6825 - loss: 0.6023 - val_accuracy: 0.6587 - val_loss: 0.6423\n",
      "Epoch 5/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6618 - loss: 0.6045 - val_accuracy: 0.6577 - val_loss: 0.6430\n",
      "Epoch 6/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6808 - loss: 0.6051 - val_accuracy: 0.6587 - val_loss: 0.6418\n",
      "Epoch 7/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6740 - loss: 0.6091 - val_accuracy: 0.6557 - val_loss: 0.6429\n",
      "Epoch 8/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6711 - loss: 0.6024 - val_accuracy: 0.6597 - val_loss: 0.6414\n",
      "Epoch 9/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6682 - loss: 0.6080 - val_accuracy: 0.6597 - val_loss: 0.6418\n",
      "Epoch 10/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6521 - loss: 0.6132 - val_accuracy: 0.6587 - val_loss: 0.6416\n",
      "Epoch 11/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6697 - loss: 0.6056 - val_accuracy: 0.6597 - val_loss: 0.6424\n",
      "Epoch 12/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6720 - loss: 0.6013 - val_accuracy: 0.6587 - val_loss: 0.6416\n",
      "Epoch 13/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6686 - loss: 0.6102 - val_accuracy: 0.6597 - val_loss: 0.6424\n",
      "Epoch 14/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6569 - loss: 0.6118 - val_accuracy: 0.6607 - val_loss: 0.6409\n",
      "Epoch 15/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6661 - loss: 0.6131 - val_accuracy: 0.6587 - val_loss: 0.6414\n",
      "Epoch 16/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6517 - loss: 0.6181 - val_accuracy: 0.6587 - val_loss: 0.6424\n",
      "Epoch 17/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6698 - loss: 0.6041 - val_accuracy: 0.6617 - val_loss: 0.6408\n",
      "Epoch 18/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6620 - loss: 0.6156 - val_accuracy: 0.6577 - val_loss: 0.6426\n",
      "Epoch 19/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6550 - loss: 0.6253 - val_accuracy: 0.6597 - val_loss: 0.6409\n",
      "Epoch 20/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6791 - loss: 0.6002 - val_accuracy: 0.6587 - val_loss: 0.6414\n",
      "Epoch 21/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6728 - loss: 0.6039 - val_accuracy: 0.6637 - val_loss: 0.6404\n",
      "Epoch 22/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6703 - loss: 0.6056 - val_accuracy: 0.6597 - val_loss: 0.6416\n",
      "Epoch 23/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6597 - loss: 0.6158 - val_accuracy: 0.6597 - val_loss: 0.6411\n",
      "Epoch 24/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6533 - loss: 0.6091 - val_accuracy: 0.6487 - val_loss: 0.6430\n",
      "Epoch 25/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6795 - loss: 0.6031 - val_accuracy: 0.6597 - val_loss: 0.6421\n",
      "Epoch 26/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6710 - loss: 0.6046 - val_accuracy: 0.6597 - val_loss: 0.6417\n",
      "Epoch 27/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6742 - loss: 0.6004 - val_accuracy: 0.6487 - val_loss: 0.6428\n",
      "Epoch 28/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6646 - loss: 0.6112 - val_accuracy: 0.6547 - val_loss: 0.6425\n",
      "Epoch 29/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6782 - loss: 0.6057 - val_accuracy: 0.6517 - val_loss: 0.6426\n",
      "Epoch 30/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6574 - loss: 0.6192 - val_accuracy: 0.6477 - val_loss: 0.6428\n",
      "Epoch 31/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6734 - loss: 0.6039 - val_accuracy: 0.6597 - val_loss: 0.6419\n",
      "Epoch 32/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6524 - loss: 0.6121 - val_accuracy: 0.6597 - val_loss: 0.6414\n",
      "Epoch 33/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6696 - loss: 0.6137 - val_accuracy: 0.6597 - val_loss: 0.6415\n",
      "Epoch 34/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6755 - loss: 0.6072 - val_accuracy: 0.6597 - val_loss: 0.6416\n",
      "Epoch 35/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6634 - loss: 0.6137 - val_accuracy: 0.6467 - val_loss: 0.6427\n",
      "Epoch 36/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6711 - loss: 0.6081 - val_accuracy: 0.6587 - val_loss: 0.6408\n",
      "Epoch 37/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6488 - loss: 0.6194 - val_accuracy: 0.6507 - val_loss: 0.6423\n",
      "Epoch 38/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6652 - loss: 0.6059 - val_accuracy: 0.6597 - val_loss: 0.6415\n",
      "Epoch 39/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6635 - loss: 0.6077 - val_accuracy: 0.6597 - val_loss: 0.6413\n",
      "Epoch 40/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6767 - loss: 0.5969 - val_accuracy: 0.6577 - val_loss: 0.6417\n",
      "Epoch 41/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6848 - loss: 0.6020 - val_accuracy: 0.6477 - val_loss: 0.6427\n",
      "Epoch 42/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6743 - loss: 0.6108 - val_accuracy: 0.6597 - val_loss: 0.6409\n",
      "Epoch 43/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6668 - loss: 0.6109 - val_accuracy: 0.6597 - val_loss: 0.6410\n",
      "Epoch 44/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6617 - loss: 0.6103 - val_accuracy: 0.6587 - val_loss: 0.6406\n",
      "Epoch 45/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6842 - loss: 0.5983 - val_accuracy: 0.6607 - val_loss: 0.6414\n",
      "Epoch 46/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6668 - loss: 0.6059 - val_accuracy: 0.6537 - val_loss: 0.6419\n",
      "Epoch 47/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6683 - loss: 0.6109 - val_accuracy: 0.6597 - val_loss: 0.6409\n",
      "Epoch 48/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6586 - loss: 0.6065 - val_accuracy: 0.6487 - val_loss: 0.6421\n",
      "Epoch 49/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6539 - loss: 0.6155 - val_accuracy: 0.6587 - val_loss: 0.6405\n",
      "Epoch 50/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6681 - loss: 0.6068 - val_accuracy: 0.6597 - val_loss: 0.6411\n",
      "Epoch 51/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6670 - loss: 0.6075 - val_accuracy: 0.6597 - val_loss: 0.6410\n",
      "Epoch 52/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6560 - loss: 0.6136 - val_accuracy: 0.6597 - val_loss: 0.6399\n",
      "Epoch 53/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6550 - loss: 0.6141 - val_accuracy: 0.6597 - val_loss: 0.6406\n",
      "Epoch 54/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6734 - loss: 0.6039 - val_accuracy: 0.6597 - val_loss: 0.6402\n",
      "Epoch 55/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6675 - loss: 0.6084 - val_accuracy: 0.6467 - val_loss: 0.6423\n",
      "Epoch 56/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6643 - loss: 0.6056 - val_accuracy: 0.6587 - val_loss: 0.6409\n",
      "Epoch 57/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6667 - loss: 0.6164 - val_accuracy: 0.6597 - val_loss: 0.6401\n",
      "Epoch 58/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6636 - loss: 0.6128 - val_accuracy: 0.6607 - val_loss: 0.6395\n",
      "Epoch 59/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6697 - loss: 0.6067 - val_accuracy: 0.6587 - val_loss: 0.6413\n",
      "Epoch 60/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6721 - loss: 0.6052 - val_accuracy: 0.6597 - val_loss: 0.6409\n",
      "Epoch 61/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6846 - loss: 0.5965 - val_accuracy: 0.6607 - val_loss: 0.6410\n",
      "Epoch 62/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6710 - loss: 0.6011 - val_accuracy: 0.6577 - val_loss: 0.6414\n",
      "Epoch 63/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6804 - loss: 0.5989 - val_accuracy: 0.6597 - val_loss: 0.6404\n",
      "Epoch 64/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6684 - loss: 0.6062 - val_accuracy: 0.6587 - val_loss: 0.6412\n",
      "Epoch 65/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6626 - loss: 0.6049 - val_accuracy: 0.6597 - val_loss: 0.6406\n",
      "Epoch 66/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6699 - loss: 0.6117 - val_accuracy: 0.6597 - val_loss: 0.6403\n",
      "Epoch 67/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6742 - loss: 0.6047 - val_accuracy: 0.6567 - val_loss: 0.6412\n",
      "Epoch 68/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6666 - loss: 0.6124 - val_accuracy: 0.6597 - val_loss: 0.6407\n",
      "Epoch 69/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6661 - loss: 0.6102 - val_accuracy: 0.6597 - val_loss: 0.6406\n",
      "Epoch 70/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6654 - loss: 0.6082 - val_accuracy: 0.6597 - val_loss: 0.6404\n",
      "Epoch 71/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6664 - loss: 0.6100 - val_accuracy: 0.6597 - val_loss: 0.6403\n",
      "Epoch 72/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6605 - loss: 0.6045 - val_accuracy: 0.6597 - val_loss: 0.6403\n",
      "Epoch 73/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6592 - loss: 0.6114 - val_accuracy: 0.6597 - val_loss: 0.6402\n",
      "Epoch 74/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6693 - loss: 0.6056 - val_accuracy: 0.6597 - val_loss: 0.6404\n",
      "Epoch 75/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6564 - loss: 0.6146 - val_accuracy: 0.6597 - val_loss: 0.6398\n",
      "Epoch 76/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6526 - loss: 0.6168 - val_accuracy: 0.6597 - val_loss: 0.6398\n",
      "Epoch 77/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6730 - loss: 0.6011 - val_accuracy: 0.6597 - val_loss: 0.6400\n",
      "Epoch 78/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6723 - loss: 0.6095 - val_accuracy: 0.6597 - val_loss: 0.6394\n",
      "Epoch 79/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6667 - loss: 0.6058 - val_accuracy: 0.6597 - val_loss: 0.6399\n",
      "Epoch 80/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6719 - loss: 0.6081 - val_accuracy: 0.6597 - val_loss: 0.6404\n",
      "Epoch 81/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6640 - loss: 0.6136 - val_accuracy: 0.6597 - val_loss: 0.6391\n",
      "Epoch 82/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6573 - loss: 0.6120 - val_accuracy: 0.6597 - val_loss: 0.6400\n",
      "Epoch 83/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6652 - loss: 0.6089 - val_accuracy: 0.6587 - val_loss: 0.6397\n",
      "Epoch 84/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6509 - loss: 0.6129 - val_accuracy: 0.6587 - val_loss: 0.6404\n",
      "Epoch 85/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6477 - loss: 0.6218 - val_accuracy: 0.6597 - val_loss: 0.6400\n",
      "Epoch 86/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6773 - loss: 0.5984 - val_accuracy: 0.6597 - val_loss: 0.6402\n",
      "Epoch 87/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6650 - loss: 0.6075 - val_accuracy: 0.6597 - val_loss: 0.6398\n",
      "Epoch 88/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6651 - loss: 0.6089 - val_accuracy: 0.6587 - val_loss: 0.6393\n",
      "Epoch 89/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6699 - loss: 0.6079 - val_accuracy: 0.6587 - val_loss: 0.6393\n",
      "Epoch 90/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6706 - loss: 0.6029 - val_accuracy: 0.6587 - val_loss: 0.6398\n",
      "Epoch 91/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6511 - loss: 0.6239 - val_accuracy: 0.6587 - val_loss: 0.6392\n",
      "Epoch 92/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6796 - loss: 0.6124 - val_accuracy: 0.6597 - val_loss: 0.6389\n",
      "Epoch 93/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6717 - loss: 0.6057 - val_accuracy: 0.6597 - val_loss: 0.6390\n",
      "Epoch 94/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6612 - loss: 0.6130 - val_accuracy: 0.6617 - val_loss: 0.6384\n",
      "Epoch 95/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6645 - loss: 0.6033 - val_accuracy: 0.6597 - val_loss: 0.6387\n",
      "Epoch 96/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6695 - loss: 0.6066 - val_accuracy: 0.6597 - val_loss: 0.6390\n",
      "Epoch 97/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6774 - loss: 0.6066 - val_accuracy: 0.6597 - val_loss: 0.6400\n",
      "Epoch 98/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6667 - loss: 0.6100 - val_accuracy: 0.6467 - val_loss: 0.6409\n",
      "Epoch 99/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6643 - loss: 0.6130 - val_accuracy: 0.6597 - val_loss: 0.6387\n",
      "Epoch 100/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6591 - loss: 0.6144 - val_accuracy: 0.6597 - val_loss: 0.6386\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n",
      "LSTM Accuracy: 0.6597\n",
      "\n",
      "LSTM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.64      0.68       561\n",
      "           1       0.60      0.69      0.64       441\n",
      "\n",
      "    accuracy                           0.66      1002\n",
      "   macro avg       0.66      0.66      0.66      1002\n",
      "weighted avg       0.67      0.66      0.66      1002\n",
      "\n",
      "\n",
      "LSTM Confusion Matrix:\n",
      "[[357 204]\n",
      " [137 304]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Tworzenie modelu LSTM\n",
    "lstm_model = Sequential()\n",
    "\n",
    "# Dodaj warstwę LSTM\n",
    "lstm_model.add(LSTM(units=50, return_sequences=False, input_shape=(X_train.shape[1], 1)))\n",
    "\n",
    "# Dodaj warstwę Dropout dla zapobiegania overfittingowi\n",
    "lstm_model.add(Dropout(0.2))\n",
    "\n",
    "# Dodaj warstwę Dense (wyjściowa warstwa klasyfikatora)\n",
    "lstm_model.add(Dense(units=1, activation='sigmoid'))  # Zakładając klasyfikację binarną\n",
    "\n",
    "# Kompilowanie modelu\n",
    "lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Trenowanie modelu\n",
    "lstm_model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Predykcja na zbiorze testowym\n",
    "y_pred_lstm = (lstm_model.predict(X_test) > 0.5).astype(int)\n",
    "\n",
    "# Ocena modelu\n",
    "accuracy_lstm = accuracy_score(y_test, y_pred_lstm)\n",
    "print(f\"LSTM Accuracy: {accuracy_lstm:.4f}\")\n",
    "print(\"\\nLSTM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_lstm))\n",
    "print(\"\\nLSTM Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_lstm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Neural Network:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pedro/python_env/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.6748 - loss: 0.6442 - val_accuracy: 0.6677 - val_loss: 0.6379\n",
      "Epoch 2/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6705 - loss: 0.6046 - val_accuracy: 0.6597 - val_loss: 0.6380\n",
      "Epoch 3/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6607 - loss: 0.6162 - val_accuracy: 0.6597 - val_loss: 0.6379\n",
      "Epoch 4/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6658 - loss: 0.6136 - val_accuracy: 0.6417 - val_loss: 0.6409\n",
      "Epoch 5/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6733 - loss: 0.6071 - val_accuracy: 0.6597 - val_loss: 0.6366\n",
      "Epoch 6/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6663 - loss: 0.6087 - val_accuracy: 0.6597 - val_loss: 0.6364\n",
      "Epoch 7/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6608 - loss: 0.6151 - val_accuracy: 0.6467 - val_loss: 0.6400\n",
      "Epoch 8/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6515 - loss: 0.6180 - val_accuracy: 0.6607 - val_loss: 0.6382\n",
      "Epoch 9/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6622 - loss: 0.6156 - val_accuracy: 0.6327 - val_loss: 0.6436\n",
      "Epoch 10/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6706 - loss: 0.6098 - val_accuracy: 0.6617 - val_loss: 0.6356\n",
      "Epoch 11/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6735 - loss: 0.6055 - val_accuracy: 0.6337 - val_loss: 0.6430\n",
      "Epoch 12/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6672 - loss: 0.6093 - val_accuracy: 0.6667 - val_loss: 0.6336\n",
      "Epoch 13/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6568 - loss: 0.6152 - val_accuracy: 0.6677 - val_loss: 0.6348\n",
      "Epoch 14/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6701 - loss: 0.6012 - val_accuracy: 0.6597 - val_loss: 0.6377\n",
      "Epoch 15/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6578 - loss: 0.6133 - val_accuracy: 0.6587 - val_loss: 0.6369\n",
      "Epoch 16/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6739 - loss: 0.6014 - val_accuracy: 0.6417 - val_loss: 0.6395\n",
      "Epoch 17/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6700 - loss: 0.6070 - val_accuracy: 0.6677 - val_loss: 0.6345\n",
      "Epoch 18/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6517 - loss: 0.6130 - val_accuracy: 0.6467 - val_loss: 0.6390\n",
      "Epoch 19/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6850 - loss: 0.5943 - val_accuracy: 0.6667 - val_loss: 0.6348\n",
      "Epoch 20/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6575 - loss: 0.6170 - val_accuracy: 0.6417 - val_loss: 0.6405\n",
      "Epoch 21/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6629 - loss: 0.6149 - val_accuracy: 0.6597 - val_loss: 0.6373\n",
      "Epoch 22/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6854 - loss: 0.5940 - val_accuracy: 0.6597 - val_loss: 0.6365\n",
      "Epoch 23/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6768 - loss: 0.6014 - val_accuracy: 0.6587 - val_loss: 0.6375\n",
      "Epoch 24/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6555 - loss: 0.6106 - val_accuracy: 0.6597 - val_loss: 0.6369\n",
      "Epoch 25/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6823 - loss: 0.6005 - val_accuracy: 0.6647 - val_loss: 0.6348\n",
      "Epoch 26/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6658 - loss: 0.6123 - val_accuracy: 0.6297 - val_loss: 0.6447\n",
      "Epoch 27/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6798 - loss: 0.6018 - val_accuracy: 0.6397 - val_loss: 0.6407\n",
      "Epoch 28/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6557 - loss: 0.6110 - val_accuracy: 0.6717 - val_loss: 0.6333\n",
      "Epoch 29/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6709 - loss: 0.6053 - val_accuracy: 0.6457 - val_loss: 0.6391\n",
      "Epoch 30/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6612 - loss: 0.6113 - val_accuracy: 0.6587 - val_loss: 0.6379\n",
      "Epoch 31/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6732 - loss: 0.5995 - val_accuracy: 0.6347 - val_loss: 0.6423\n",
      "Epoch 32/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6522 - loss: 0.6118 - val_accuracy: 0.6637 - val_loss: 0.6349\n",
      "Epoch 33/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6574 - loss: 0.6118 - val_accuracy: 0.6597 - val_loss: 0.6372\n",
      "Epoch 34/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6587 - loss: 0.6159 - val_accuracy: 0.6597 - val_loss: 0.6363\n",
      "Epoch 35/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6684 - loss: 0.6054 - val_accuracy: 0.6377 - val_loss: 0.6415\n",
      "Epoch 36/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6797 - loss: 0.6003 - val_accuracy: 0.6617 - val_loss: 0.6357\n",
      "Epoch 37/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6584 - loss: 0.6087 - val_accuracy: 0.6457 - val_loss: 0.6389\n",
      "Epoch 38/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6759 - loss: 0.5962 - val_accuracy: 0.6637 - val_loss: 0.6351\n",
      "Epoch 39/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6654 - loss: 0.6154 - val_accuracy: 0.6417 - val_loss: 0.6411\n",
      "Epoch 40/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6669 - loss: 0.6033 - val_accuracy: 0.6587 - val_loss: 0.6367\n",
      "Epoch 41/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6735 - loss: 0.6050 - val_accuracy: 0.6587 - val_loss: 0.6363\n",
      "Epoch 42/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6702 - loss: 0.6044 - val_accuracy: 0.6667 - val_loss: 0.6345\n",
      "Epoch 43/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6848 - loss: 0.5997 - val_accuracy: 0.6597 - val_loss: 0.6357\n",
      "Epoch 44/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6559 - loss: 0.6227 - val_accuracy: 0.6587 - val_loss: 0.6366\n",
      "Epoch 45/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6688 - loss: 0.6087 - val_accuracy: 0.6637 - val_loss: 0.6351\n",
      "Epoch 46/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6713 - loss: 0.6035 - val_accuracy: 0.6407 - val_loss: 0.6409\n",
      "Epoch 47/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6672 - loss: 0.6053 - val_accuracy: 0.6417 - val_loss: 0.6399\n",
      "Epoch 48/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6691 - loss: 0.6103 - val_accuracy: 0.6607 - val_loss: 0.6353\n",
      "Epoch 49/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6712 - loss: 0.6064 - val_accuracy: 0.6667 - val_loss: 0.6335\n",
      "Epoch 50/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6609 - loss: 0.6047 - val_accuracy: 0.6637 - val_loss: 0.6349\n",
      "Epoch 51/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6732 - loss: 0.6062 - val_accuracy: 0.6597 - val_loss: 0.6354\n",
      "Epoch 52/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6764 - loss: 0.5983 - val_accuracy: 0.6597 - val_loss: 0.6369\n",
      "Epoch 53/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6642 - loss: 0.6045 - val_accuracy: 0.6417 - val_loss: 0.6397\n",
      "Epoch 54/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6642 - loss: 0.6096 - val_accuracy: 0.6657 - val_loss: 0.6338\n",
      "Epoch 55/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6709 - loss: 0.6053 - val_accuracy: 0.6597 - val_loss: 0.6373\n",
      "Epoch 56/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6574 - loss: 0.6072 - val_accuracy: 0.6637 - val_loss: 0.6349\n",
      "Epoch 57/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6723 - loss: 0.6037 - val_accuracy: 0.6377 - val_loss: 0.6419\n",
      "Epoch 58/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6755 - loss: 0.6077 - val_accuracy: 0.6766 - val_loss: 0.6310\n",
      "Epoch 59/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6601 - loss: 0.6156 - val_accuracy: 0.6617 - val_loss: 0.6354\n",
      "Epoch 60/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6727 - loss: 0.6051 - val_accuracy: 0.6597 - val_loss: 0.6374\n",
      "Epoch 61/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6668 - loss: 0.6036 - val_accuracy: 0.6377 - val_loss: 0.6418\n",
      "Epoch 62/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6638 - loss: 0.5991 - val_accuracy: 0.6717 - val_loss: 0.6332\n",
      "Epoch 63/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6690 - loss: 0.6094 - val_accuracy: 0.6417 - val_loss: 0.6398\n",
      "Epoch 64/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6735 - loss: 0.6069 - val_accuracy: 0.6677 - val_loss: 0.6341\n",
      "Epoch 65/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6703 - loss: 0.6107 - val_accuracy: 0.6417 - val_loss: 0.6401\n",
      "Epoch 66/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6666 - loss: 0.6096 - val_accuracy: 0.6667 - val_loss: 0.6350\n",
      "Epoch 67/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6632 - loss: 0.6086 - val_accuracy: 0.6597 - val_loss: 0.6364\n",
      "Epoch 68/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6813 - loss: 0.5926 - val_accuracy: 0.6557 - val_loss: 0.6383\n",
      "Epoch 69/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6608 - loss: 0.6081 - val_accuracy: 0.6507 - val_loss: 0.6385\n",
      "Epoch 70/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6632 - loss: 0.6073 - val_accuracy: 0.6277 - val_loss: 0.6459\n",
      "Epoch 71/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6799 - loss: 0.6011 - val_accuracy: 0.6587 - val_loss: 0.6379\n",
      "Epoch 72/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6716 - loss: 0.6052 - val_accuracy: 0.6467 - val_loss: 0.6387\n",
      "Epoch 73/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6777 - loss: 0.6056 - val_accuracy: 0.6677 - val_loss: 0.6334\n",
      "Epoch 74/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6732 - loss: 0.6027 - val_accuracy: 0.6407 - val_loss: 0.6395\n",
      "Epoch 75/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6679 - loss: 0.6146 - val_accuracy: 0.6477 - val_loss: 0.6387\n",
      "Epoch 76/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6536 - loss: 0.6128 - val_accuracy: 0.6597 - val_loss: 0.6362\n",
      "Epoch 77/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6516 - loss: 0.6078 - val_accuracy: 0.6597 - val_loss: 0.6376\n",
      "Epoch 78/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6653 - loss: 0.6094 - val_accuracy: 0.6667 - val_loss: 0.6335\n",
      "Epoch 79/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6687 - loss: 0.6044 - val_accuracy: 0.6587 - val_loss: 0.6376\n",
      "Epoch 80/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6737 - loss: 0.6059 - val_accuracy: 0.6487 - val_loss: 0.6387\n",
      "Epoch 81/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6710 - loss: 0.6017 - val_accuracy: 0.6587 - val_loss: 0.6365\n",
      "Epoch 82/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6622 - loss: 0.6053 - val_accuracy: 0.6457 - val_loss: 0.6391\n",
      "Epoch 83/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6630 - loss: 0.6112 - val_accuracy: 0.6597 - val_loss: 0.6378\n",
      "Epoch 84/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6672 - loss: 0.6083 - val_accuracy: 0.6417 - val_loss: 0.6400\n",
      "Epoch 85/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6667 - loss: 0.6069 - val_accuracy: 0.6437 - val_loss: 0.6403\n",
      "Epoch 86/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6623 - loss: 0.6074 - val_accuracy: 0.6327 - val_loss: 0.6430\n",
      "Epoch 87/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6746 - loss: 0.5938 - val_accuracy: 0.6587 - val_loss: 0.6378\n",
      "Epoch 88/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6680 - loss: 0.6044 - val_accuracy: 0.6337 - val_loss: 0.6428\n",
      "Epoch 89/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6567 - loss: 0.6202 - val_accuracy: 0.6467 - val_loss: 0.6394\n",
      "Epoch 90/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6692 - loss: 0.6109 - val_accuracy: 0.6597 - val_loss: 0.6362\n",
      "Epoch 91/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6730 - loss: 0.5983 - val_accuracy: 0.6667 - val_loss: 0.6349\n",
      "Epoch 92/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6593 - loss: 0.6154 - val_accuracy: 0.6677 - val_loss: 0.6349\n",
      "Epoch 93/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6636 - loss: 0.6053 - val_accuracy: 0.6587 - val_loss: 0.6379\n",
      "Epoch 94/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6738 - loss: 0.6045 - val_accuracy: 0.6477 - val_loss: 0.6392\n",
      "Epoch 95/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6750 - loss: 0.6082 - val_accuracy: 0.6597 - val_loss: 0.6369\n",
      "Epoch 96/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6634 - loss: 0.6112 - val_accuracy: 0.6597 - val_loss: 0.6363\n",
      "Epoch 97/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6660 - loss: 0.6046 - val_accuracy: 0.6467 - val_loss: 0.6393\n",
      "Epoch 98/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6690 - loss: 0.6061 - val_accuracy: 0.6377 - val_loss: 0.6418\n",
      "Epoch 99/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6563 - loss: 0.6128 - val_accuracy: 0.6437 - val_loss: 0.6405\n",
      "Epoch 100/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6756 - loss: 0.5980 - val_accuracy: 0.6597 - val_loss: 0.6364\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Neural Network Accuracy: 0.6597\n",
      "\n",
      "Neural Network Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.64      0.68       561\n",
      "           1       0.60      0.69      0.64       441\n",
      "\n",
      "    accuracy                           0.66      1002\n",
      "   macro avg       0.66      0.66      0.66      1002\n",
      "weighted avg       0.67      0.66      0.66      1002\n",
      "\n",
      "\n",
      "Neural Network Confusion Matrix:\n",
      "[[357 204]\n",
      " [137 304]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_nn = (model.predict(X_test) > 0.5).astype(int)\n",
    "\n",
    "accuracy_nn = accuracy_score(y_test, y_pred_nn)\n",
    "print(f\"Neural Network Accuracy: {accuracy_nn:.4f}\")\n",
    "print(\"\\nNeural Network Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_nn))\n",
    "print(\"\\nNeural Network Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.25, random_state=42\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
